{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A Dialogue-Based SNOMED Prediction Benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare Data\n",
        "For data, I decided to use [Synthea](https://synthea.mitre.org/downloads) 1K sample dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_root = '../../data/synthea_sample_data_csv_nov2021/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"patient_id\": \"339144f8-50e1-633e-a013-f361391c4cff\",\n",
            "  \"oracle_context\": \"Age: 27\\nGender: M\\nLocation: Boston, Massachusetts\\nConditions: Sprain of ankle; Hypertension; Acute viral pharyngitis (disorder); Viral sinusitis (disorder); Refugee (person)\\nObservations:\\n- Body Height: 166.8\\n- Pain severity - 0-10 verbal numeric rating [Score] - Reported: 3.0\\n- Body Weight: 70.9\\n- Body Mass Index: 25.5\\n- Body mass index (BMI) [Percentile] Per age and gender: 94.0\\n- Diastolic Blood Pressure: 82.0\\n- Systolic Blood Pressure: 129.0\\n- Heart rate: 87.0\\n- Respiratory rate: 15.0\\n- Tobacco smoking status NHIS: Never smoker\",\n",
            "  \"snomed_gold\": [\n",
            "    \"44465007 - Sprain of ankle\",\n",
            "    \"59621000 - Hypertension\",\n",
            "    \"195662009 - Acute viral pharyngitis (disorder)\",\n",
            "    \"444814009 - Viral sinusitis (disorder)\",\n",
            "    \"446654005 - Refugee (person)\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"patient_id\": \"d488232e-bf14-4bed-08c0-a82f34b6a197\",\n",
            "  \"oracle_context\": \"Age: 22\\nGender: F\\nLocation: Hingham, Massachusetts\\nConditions: Acute viral pharyngitis (disorder); Viral sinusitis (disorder); Acute bronchitis (disorder); Normal pregnancy\\nObservations:\\n- Body Height: 131.2\\n- Pain severity - 0-10 verbal numeric rating [Score] - Reported: 2.0\\n- Body Weight: 28.5\\n- Body Mass Index: 16.5\\n- Body mass index (BMI) [Percentile] Per age and gender: 54.1\\n- Diastolic Blood Pressure: 82.0\\n- Systolic Blood Pressure: 106.0\\n- Heart rate: 67.0\\n- Respiratory rate: 15.0\\n- Tobacco smoking status NHIS: Never smoker\",\n",
            "  \"snomed_gold\": [\n",
            "    \"195662009 - Acute viral pharyngitis (disorder)\",\n",
            "    \"444814009 - Viral sinusitis (disorder)\",\n",
            "    \"10509002 - Acute bronchitis (disorder)\",\n",
            "    \"72892002 - Normal pregnancy\"\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"patient_id\": \"faac724a-a9e9-be66-fe1e-3044dc0ba8ea\",\n",
            "  \"oracle_context\": \"Age: 5\\nGender: F\\nLocation: New Marlborough, Massachusetts\\nConditions: Suspected COVID-19; COVID-19\\nObservations:\\n- Body Height: 49.8\\n- Pain severity - 0-10 verbal numeric rating [Score] - Reported: 2.0\\n- Body Weight: 3.8\\n- Weight-for-length Per age and sex: 79.9\\n- Head Occipital-frontal circumference: 33.5\\n- Diastolic Blood Pressure: 81.0\\n- Systolic Blood Pressure: 104.0\\n- Heart rate: 88.0\\n- Respiratory rate: 13.0\\n- Leukocytes [#/volume] in Blood by Automated count: 5.1\",\n",
            "  \"snomed_gold\": [\n",
            "    \"840544004 - Suspected COVID-19\",\n",
            "    \"840539006 - COVID-19\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Load CSVs\n",
        "patients_df = pd.read_csv(os.path.join(data_root, \"patients.csv\"))\n",
        "conditions_df = pd.read_csv(os.path.join(data_root, \"conditions.csv\"))\n",
        "observations_df = pd.read_csv(os.path.join(data_root, \"observations.csv\"))\n",
        "\n",
        "# Number of patients to sample\n",
        "SAMPLE_SIZE = 500\n",
        "\n",
        "# Sample patients\n",
        "sample_patient_ids = patients_df['Id'].sample(SAMPLE_SIZE, random_state=42).tolist()\n",
        "sample_patients = patients_df[patients_df['Id'].isin(sample_patient_ids)]\n",
        "sample_conditions = conditions_df[conditions_df['PATIENT'].isin(sample_patient_ids)]\n",
        "sample_observations = observations_df[observations_df['PATIENT'].isin(sample_patient_ids)]\n",
        "\n",
        "# Build structured context per patient\n",
        "flat_records = []\n",
        "\n",
        "for _, patient in sample_patients.iterrows():\n",
        "    pid = patient['Id']\n",
        "    age = 2025 - int(patient['BIRTHDATE'][:4])\n",
        "    gender = patient['GENDER']\n",
        "    city = patient['CITY']\n",
        "    state = patient['STATE']\n",
        "\n",
        "    # Conditions with filtering\n",
        "    raw_conds = (\n",
        "        sample_conditions[sample_conditions['PATIENT'] == pid]['DESCRIPTION']\n",
        "        .dropna()\n",
        "        .unique()\n",
        "        .tolist()\n",
        "    )\n",
        "\n",
        "    # Filter valid condition rows (as DataFrame)\n",
        "    irrelevant_keywords = [\"employment\", \"education\", \"finding\", \"social\", \"victim\", \"student\", \"contact\"]\n",
        "    valid_cond_df = sample_conditions[\n",
        "        (sample_conditions['PATIENT'] == pid) &\n",
        "        (~sample_conditions['DESCRIPTION'].str.lower().str.contains('|'.join(irrelevant_keywords)))\n",
        "    ][['DESCRIPTION', 'CODE']].dropna().drop_duplicates()\n",
        "\n",
        "    # SNOMED gold codes\n",
        "    snomed_gold = [\n",
        "        f\"{row['CODE']} - {row['DESCRIPTION']}\" for _, row in valid_cond_df.iterrows()\n",
        "    ]\n",
        "\n",
        "    # Conditions (for oracle_context)\n",
        "    filtered_conds = valid_cond_df['DESCRIPTION'].tolist()\n",
        "\n",
        "    # Observations\n",
        "    obs_df = sample_observations[sample_observations['PATIENT'] == pid]\n",
        "    obs_pairs = []\n",
        "    for _, row in obs_df.iterrows():\n",
        "        label = row['DESCRIPTION']\n",
        "        value = row['VALUE']\n",
        "        if pd.notna(label) and pd.notna(value):\n",
        "            obs_pairs.append(f\"{label}: {value}\")\n",
        "\n",
        "    # Create flat context\n",
        "    context = f\"Age: {age}\\nGender: {gender}\\nLocation: {city}, {state}\"\n",
        "    if filtered_conds:\n",
        "        context += \"\\nConditions: \" + \"; \".join(filtered_conds[:10])\n",
        "    if obs_pairs:\n",
        "        context += \"\\nObservations:\\n- \" + \"\\n- \".join(obs_pairs[:10])\n",
        "\n",
        "    flat_records.append({\n",
        "        \"patient_id\": pid,\n",
        "        \"oracle_context\": context,\n",
        "        \"snomed_gold\": snomed_gold[:10]\n",
        "    })\n",
        "\n",
        "# Optional: Save to JSON\n",
        "import json\n",
        "with open(\"synthea_oracle_context.json\", \"w\") as f:\n",
        "    json.dump(flat_records, f, indent=2)\n",
        "\n",
        "# Print a few samples\n",
        "for record in flat_records[:3]:\n",
        "    print(json.dumps(record, indent=2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 11/500 [00:05<03:17,  2.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 4c7bbf23-68f4-86e8-c61e-1a1b1e81c4ea: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 34/500 [00:10<01:45,  4.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for eb2f8ba1-fd23-fdbb-dbe3-484a3d58244e: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|▊         | 42/500 [00:13<02:31,  3.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 1a3c4dbc-9cf9-3967-ac48-389057e4f2aa: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|▉         | 44/500 [00:13<02:07,  3.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 70c444f6-2f20-e9c3-0c1c-13fab72f9a4a: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|▉         | 48/500 [00:14<01:45,  4.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 72b71d33-b242-8f86-7ce0-198b3dfd3bf1: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 69/500 [00:20<01:57,  3.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 5b0609a7-49e8-65b4-dc32-9edc8301c646: Expecting ',' delimiter: line 6 column 89 (char 656)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 75/500 [00:22<01:45,  4.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 9bbc77f6-c1e1-0c48-c64e-eb5958f15faf: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 80/500 [00:23<01:44,  4.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 93d970b1-94b9-8455-de35-0bcc1a45eb7b: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 91/500 [00:26<01:58,  3.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 07a1f80c-f4e2-8e91-5913-270fc6afa25d: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 92/500 [00:27<02:10,  3.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for eebbb6c9-87b3-9978-5eab-84edacbccc7c: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|██▎       | 118/500 [00:35<01:39,  3.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 520fdcd4-8d55-8a00-67b8-a0d61a50d9b5: Expecting value: line 1 column 1 (char 0)\n",
            "⚠️ Error for c5340af3-dde7-d403-78dd-bf20a03f0238: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 131/500 [00:39<02:14,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 9724e8c9-3f30-702a-f75a-95082c024706: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 139/500 [00:41<01:42,  3.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 1eb1b9e0-4cdf-7910-e76d-9f7534bcc7f0: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 160/500 [00:47<02:15,  2.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 08c885d3-43c9-efd4-e8b3-c6140832b18f: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 170/500 [00:50<01:14,  4.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for b795bf03-28fb-ad1d-5a43-3e44422700a7: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 187/500 [00:55<01:59,  2.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 3fda13ae-c868-c505-10ee-3f6d4b694b84: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 200/500 [01:00<02:03,  2.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for d4dd09e5-8eae-7136-407c-df2715f2643b: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|████▏     | 209/500 [01:03<01:35,  3.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 9ac43dbb-44d6-871e-b411-a1c18c61b55e: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 220/500 [01:06<01:00,  4.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for db827d6a-d1c7-cd51-9b86-626ab88d58da: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 234/500 [01:10<00:56,  4.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for ef82862b-c0f8-7440-2dcb-4d7137349f0d: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 240/500 [01:12<01:31,  2.85it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for c987d011-9807-23da-8487-4d7ce3511a86: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 252/500 [01:15<01:15,  3.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for c1c5bcd1-d232-8de3-7e0f-3ef13280455c: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████▏    | 257/500 [01:16<00:51,  4.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 68f34b8e-efce-ce3e-836d-a815503c7b56: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 52%|█████▏    | 261/500 [01:18<01:32,  2.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 2376720a-56ca-5474-3737-32cf783a169c: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 54%|█████▎    | 268/500 [01:19<01:01,  3.78it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 9e84e569-7adc-ff42-ccdb-9fe9c23842a6: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 281/500 [01:24<01:18,  2.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 246fb368-8991-dc93-f6a5-eca807e7dbde: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|██████    | 304/500 [01:30<01:04,  3.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 77e0ed77-2f51-7fe3-792d-ff1e0be7f3c2: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 313/500 [01:32<01:04,  2.88it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 91f3dfb6-9545-a0cf-7c12-64d89cab1db3: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 321/500 [01:34<00:38,  4.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for d7bb0340-9894-8bd0-056a-29efc5444fa0: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 64%|██████▍   | 322/500 [01:35<01:08,  2.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for ec56f618-56ed-cf49-78fd-4d561bf7cba3: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 326/500 [01:36<00:59,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 70231807-0c38-db06-806e-a73e94bcd591: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 336/500 [01:39<00:48,  3.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for d90705f0-2c2d-4126-6504-93d4da9c6f7a: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 376/500 [01:51<00:24,  4.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for ef167059-cef0-12c4-49db-993ca3a20c01: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|███████▌  | 378/500 [01:52<00:50,  2.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for ebe6f5b1-c05d-6043-33d1-83ef3dc4da13: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▊  | 393/500 [01:56<00:32,  3.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for d26086c9-4205-29b4-0e28-a77231a9724a: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 79%|███████▉  | 396/500 [01:57<00:33,  3.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for faf1d0f2-c429-72a4-5be0-e542949829ab: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|███████▉  | 399/500 [01:58<00:36,  2.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 2798ae24-ef3b-1906-6e41-a31e0fd833a0: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%|████████▏ | 408/500 [02:01<00:25,  3.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 23d4a494-443e-fe6b-d0ec-e21a762d2a90: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▋ | 432/500 [02:08<00:18,  3.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for e61fe1f4-3daa-bbeb-649a-fdae0eeee227: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 441/500 [02:11<00:22,  2.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 05801c88-9f2e-536e-9068-4b7b4431d072: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 464/500 [02:18<00:07,  4.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 3d5f91c2-0539-37c9-0691-d2bbe28c78e3: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 467/500 [02:18<00:05,  5.54it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for ce1b17d2-15ee-aa1c-bdd1-8be89ba22acf: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 94%|█████████▍| 471/500 [02:20<00:09,  3.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 123a2225-13bc-8bd7-2868-0245cb02856d: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 485/500 [02:24<00:03,  4.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 767e1d64-d100-a9ec-fe05-073c6857ffa8: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 488/500 [02:25<00:03,  3.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Error for 16374251-beab-44f9-ac53-faece4e66bc2: Expecting value: line 1 column 1 (char 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [02:29<00:00,  3.34it/s]\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import asyncio\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "client = openai.AsyncOpenAI(api_key=\"sk-proj-\") # Replace with your actual OpenAI API key to run this script\n",
        "\n",
        "# Load structured patients\n",
        "with open(\"synthea_oracle_context.json\", \"r\") as f:\n",
        "    patients = json.load(f)\n",
        "\n",
        "output_file = \"oracle_qa_finetune_data.jsonl\"\n",
        "\n",
        "def build_chat_messages(context, snomed_list):\n",
        "    gold = \"\\n\".join(snomed_list)\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\n",
        "                \"You are simulating a patient with the following medical conditions. \"\n",
        "                \"Respond in plain language without naming diagnoses unless asked. Vary your answers. \"\n",
        "                \"Focus on realistic symptoms, complaints, or feelings.\"\n",
        "            )\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"PATIENT INFO:\n",
        "            {context}\n",
        "\n",
        "            GOLD CONDITIONS (SNOMED):\n",
        "            {gold}\n",
        "\n",
        "            Generate 5 different question/answer pairs that reflect the patient's symptoms or experiences. \n",
        "            Do NOT use clinical language. Each answer should sound like something a regular person would say. \n",
        "            Only output a JSON array like this:\n",
        "            [\n",
        "                {{ \"question\": \"...\", \"answer\": \"...\" }},\n",
        "            ...\n",
        "            ]\n",
        "            \"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "def build_negative_qa_prompt(context, snomed_list):\n",
        "    gold = \"\\n\".join(snomed_list)\n",
        "    return [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"You are simulating a patient with limited medical knowledge.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"\"\"Patient Info:\n",
        "            {context}\n",
        "\n",
        "            GOLD CONDITIONS (SNOMED):\n",
        "            {gold}\n",
        "\n",
        "            TASK:\n",
        "            - Imagine a doctor is asking the patient about symptoms NOT related to the conditions above.\n",
        "            - Generate 2 question/answer pairs.\n",
        "            - The **question** should come from the doctor, phrased in plain language.\n",
        "            - The **answer** should sound like the patient is unsure or hasn’t experienced it.\n",
        "            - The patient should **not explain or speculate** — just admit uncertainty or lack of awareness.\n",
        "\n",
        "            Only output a JSON array like this:\n",
        "            [\n",
        "            {{ \"question\": \"Have you noticed any changes in your memory?\", \"answer\": \"I’m not really sure. I haven’t paid much attention to that.\" }},\n",
        "            ...\n",
        "            ]\n",
        "            \"\"\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "\n",
        "# Generate QA examples\n",
        "# Async function to process one patient\n",
        "async def process_patient(patient, sem, out_fp):\n",
        "    async with sem:\n",
        "        try:\n",
        "            # GPT call: symptom-based QAs\n",
        "            res1 = await client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=build_chat_messages(patient[\"oracle_context\"], patient[\"snomed_gold\"]),\n",
        "                temperature=0.9,\n",
        "                timeout=20,\n",
        "            )\n",
        "            qa_pairs = json.loads(res1.choices[0].message.content.strip())\n",
        "\n",
        "            # GPT call: negative QAs\n",
        "            res2 = await client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=build_negative_qa_prompt(patient[\"oracle_context\"], patient[\"snomed_gold\"]),\n",
        "                temperature=0.8,\n",
        "                timeout=20,\n",
        "            )\n",
        "            neg_pairs = json.loads(res2.choices[0].message.content.strip())\n",
        "            qa_pairs.extend(neg_pairs)\n",
        "\n",
        "            # Write to file (append mode)\n",
        "            for qa in qa_pairs:\n",
        "                record = {\n",
        "                    \"instruction\": \"Answer the user's question based on the patient context. Use lay language only.\",\n",
        "                    \"snomed_gold\": patient[\"snomed_gold\"],\n",
        "                    \"input\": f\"Patient Info:\\n{patient['oracle_context']}\\nQuestion: {qa['question']}\",\n",
        "                    \"output\": qa[\"answer\"]\n",
        "                }\n",
        "                out_fp.write(json.dumps(record) + \"\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error for {patient['patient_id']}: {str(e)}\")\n",
        "\n",
        "# Main async runner\n",
        "async def main():\n",
        "    output_path = \"oracle_qa_finetune_data.json\"\n",
        "    sem = asyncio.Semaphore(10)  # Max 10 concurrent GPT calls\n",
        "\n",
        "    with open(output_path, \"w\") as out_fp:\n",
        "        tasks = [process_patient(p, sem, out_fp) for p in patients]\n",
        "        for f in tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
        "            await f\n",
        " \n",
        " # Run the event loop\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "await main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try without fine-tune."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"biomistral/biomistral-7b\"\n",
        "local_dir = \"./biomistral-7b\"\n",
        "\n",
        "# Download and cache model/tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, cache_dir=local_dir)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, cache_dir=local_dir)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test zero-shot!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "c:\\Users\\young\\anaconda3\\envs\\aihc-ml\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:456: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Input Prompt:\n",
            " ### Instruction:\n",
            "    You are a patient. Answer the doctor's question based on the patient context given. \n",
            "    Use lay language only. Please be concise and answer in one or two short sentences.\n",
            "\n",
            "    ### Input:\n",
            "    Patient Info:\n",
            "Age: 114\n",
            "Gender: F\n",
            "Location: Westfield, Massachusetts\n",
            "Conditions: Refugee (person); Prediabetes; Anemia (disorder); Miscarriage in first trimester; Tubal pregnancy; Rheumatoid arthritis; Chronic sinusitis (disorder); Polyp of colon; Osteoporosis (disorder); Chronic intractable migraine without aura\n",
            "Observations:\n",
            "- Body Height: 161.9\n",
            "- Pain severity - 0-10 verbal numeric rating [Score] - Reported: 2.0\n",
            "- Body Weight: 72.9\n",
            "- Body Mass Index: 27.8\n",
            "- Diastolic Blood Pressure: 80.0\n",
            "- Systolic Blood Pressure: 112.0\n",
            "- Heart rate: 75.0\n",
            "- Respiratory rate: 16.0\n",
            "- Glucose: 65.4\n",
            "- Urea Nitrogen: 19.6\n",
            "Question: How have your sinus issues been lately?\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "\n",
            "🧠 Model Response:\n",
            " 1. My sinus issues have been pretty bad lately. I've been having a lot of sinus infections and congestion. I've been trying different medications and over-the-counter remedies, but nothing seems to\n",
            "\n",
            "✅ Expected (Fine-Tuned) Answer:\n",
            " My chronic sinusitis has been bothering me, making it hard to breathe at times.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Input Prompt:\n",
            " ### Instruction:\n",
            "    You are a patient. Answer the doctor's question based on the patient context given. \n",
            "    Use lay language only. Please be concise and answer in one or two short sentences.\n",
            "\n",
            "    ### Input:\n",
            "    Patient Info:\n",
            "Age: 65\n",
            "Gender: M\n",
            "Location: North Eastham, Massachusetts\n",
            "Conditions: Hypertension; Cardiac Arrest; History of cardiac arrest (situation); Viral sinusitis (disorder); Laceration of foot; Otitis media\n",
            "Observations:\n",
            "- Body Height: 186.8\n",
            "- Pain severity - 0-10 verbal numeric rating [Score] - Reported: 2.0\n",
            "- Body Weight: 85.2\n",
            "- Body Mass Index: 24.4\n",
            "- Diastolic Blood Pressure: 83.0\n",
            "- Systolic Blood Pressure: 115.0\n",
            "- Heart rate: 74.0\n",
            "- Respiratory rate: 16.0\n",
            "- Tobacco smoking status NHIS: Never smoker\n",
            "- In the past year  have you been afraid of your partner or ex-partner?: No\n",
            "Question: Do you have any trouble with blurry vision or seeing double?\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "\n",
            "🧠 Model Response:\n",
            " 1. No, I do not have any trouble with blurry vision or seeing double.\n",
            "\n",
            "✅ Expected (Fine-Tuned) Answer:\n",
            " I don't think so, but I haven't really noticed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Input Prompt:\n",
            " ### Instruction:\n",
            "    You are a patient. Answer the doctor's question based on the patient context given. \n",
            "    Use lay language only. Please be concise and answer in one or two short sentences.\n",
            "\n",
            "    ### Input:\n",
            "    Patient Info:\n",
            "Age: 13\n",
            "Gender: F\n",
            "Location: East Brookfield, Massachusetts\n",
            "Conditions: Acute bronchitis (disorder); Streptococcal sore throat (disorder); Sinusitis (disorder); Chronic sinusitis (disorder)\n",
            "Observations:\n",
            "- Body Height: 51.7\n",
            "- Pain severity - 0-10 verbal numeric rating [Score] - Reported: 2.0\n",
            "- Body Weight: 3.7\n",
            "- Weight-for-length Per age and sex: 24.0\n",
            "- Head Occipital-frontal circumference: 34.8\n",
            "- Diastolic Blood Pressure: 85.0\n",
            "- Systolic Blood Pressure: 109.0\n",
            "- Heart rate: 72.0\n",
            "- Respiratory rate: 15.0\n",
            "- Leukocytes [#/volume] in Blood by Automated count: 10.0\n",
            "Question: How have you been feeling lately?\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "\n",
            "🧠 Model Response:\n",
            " ive been feeling really sick and tired.\n",
            "\n",
            "✅ Expected (Fine-Tuned) Answer:\n",
            " I've been feeling really congested and my throat hurts a lot.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Input Prompt:\n",
            " ### Instruction:\n",
            "    You are a patient. Answer the doctor's question based on the patient context given. \n",
            "    Use lay language only. Please be concise and answer in one or two short sentences.\n",
            "\n",
            "    ### Input:\n",
            "    Patient Info:\n",
            "Age: 7\n",
            "Gender: F\n",
            "Location: Somerville, Massachusetts\n",
            "Observations:\n",
            "- Body Height: 49.4\n",
            "- Pain severity - 0-10 verbal numeric rating [Score] - Reported: 2.0\n",
            "- Body Weight: 3.1\n",
            "- Weight-for-length Per age and sex: 32.4\n",
            "- Head Occipital-frontal circumference: 33.2\n",
            "- Diastolic Blood Pressure: 82.0\n",
            "- Systolic Blood Pressure: 117.0\n",
            "- Heart rate: 67.0\n",
            "- Respiratory rate: 14.0\n",
            "- Leukocytes [#/volume] in Blood by Automated count: 8.9\n",
            "Question: Are you feeling tired or energetic lately?\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "\n",
            "🧠 Model Response:\n",
            " 7-year-old girl feeling energetic lately.\n",
            "\n",
            "✅ Expected (Fine-Tuned) Answer:\n",
            " I've been feeling pretty energetic lately!\n",
            "\n",
            "🔍 Input Prompt:\n",
            " ### Instruction:\n",
            "    You are a patient. Answer the doctor's question based on the patient context given. \n",
            "    Use lay language only. Please be concise and answer in one or two short sentences.\n",
            "\n",
            "    ### Input:\n",
            "    Patient Info:\n",
            "Age: 77\n",
            "Gender: M\n",
            "Location: Somerville, Massachusetts\n",
            "Conditions: Hypertension; Viral sinusitis (disorder); Acute bronchitis (disorder); Chronic congestive heart failure (disorder); Acute bacterial sinusitis (disorder)\n",
            "Observations:\n",
            "- Body Height: 182.8\n",
            "- Pain severity - 0-10 verbal numeric rating [Score] - Reported: 0.0\n",
            "- Body Weight: 94.0\n",
            "- Body Mass Index: 28.1\n",
            "- Diastolic Blood Pressure: 96.0\n",
            "- Systolic Blood Pressure: 155.0\n",
            "- Heart rate: 94.0\n",
            "- Respiratory rate: 14.0\n",
            "- Tobacco smoking status NHIS: Never smoker\n",
            "- In the past year  have you been afraid of your partner or ex-partner?: No\n",
            "Question: How have you been feeling lately?\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "\n",
            "🧠 Model Response:\n",
            " 77 year old male patient with chronic congestive heart failure, hypertension, acute bacterial sinusitis and viral sinusitis. Patient is a non-smoker and has no history of alcohol or drug abuse.\n",
            "\n",
            "✅ Expected (Fine-Tuned) Answer:\n",
            " I've been feeling pretty tired and a bit short of breath.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "# run 5 sample\n",
        "for _ in range(5):\n",
        "    # Load a QA sample from your dataset\n",
        "    with open(\"oracle_qa_finetune_data.json\", \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "        sample = json.loads(random.choice(lines))\n",
        "\n",
        "    # Unpack the fields\n",
        "    instruction = sample[\"instruction\"]\n",
        "    input_block = sample[\"input\"]\n",
        "    true_output = sample[\"output\"]\n",
        "\n",
        "\n",
        "    # Format prompt using your real training example\n",
        "    prompt = f\"\"\"### Instruction:\n",
        "    You are a patient. Answer the doctor's question based on the patient context given. \n",
        "    Use lay language only. Please be concise and answer in one or two short sentences.\n",
        "\n",
        "    ### Input:\n",
        "    {input_block}\n",
        "\n",
        "    ### Response:\n",
        "    \"\"\"\n",
        "\n",
        "    # Tokenize and generate\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=50,\n",
        "            do_sample=False,\n",
        "            temperature=0.6\n",
        "        )\n",
        "\n",
        "    # Decode\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    model_response = response.split(\"### Response:\")[-1].strip()\n",
        "\n",
        "    # Show comparison\n",
        "    print(\"\\n🔍 Input Prompt:\\n\", prompt)\n",
        "    print(\"\\n🧠 Model Response:\\n\", model_response)\n",
        "    print(\"\\n✅ Expected (Fine-Tuned) Answer:\\n\", true_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fine tune!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0741ff9f55d04ca4a23cfc144c0dc67e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2382 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 2.0434, 'grad_norm': 10.874444961547852, 'learning_rate': 1.9916036943744756e-05, 'epoch': 0.01}\n",
            "{'loss': 1.7315, 'grad_norm': 12.161198616027832, 'learning_rate': 1.9832073887489506e-05, 'epoch': 0.03}\n",
            "{'loss': 1.4156, 'grad_norm': 11.05747127532959, 'learning_rate': 1.974811083123426e-05, 'epoch': 0.04}\n",
            "{'loss': 1.0928, 'grad_norm': 11.315916061401367, 'learning_rate': 1.966414777497901e-05, 'epoch': 0.05}\n",
            "{'loss': 0.8984, 'grad_norm': 11.166594505310059, 'learning_rate': 1.9580184718723762e-05, 'epoch': 0.06}\n",
            "{'loss': 0.7656, 'grad_norm': 8.333418846130371, 'learning_rate': 1.9496221662468516e-05, 'epoch': 0.08}\n",
            "{'loss': 0.6807, 'grad_norm': 9.426526069641113, 'learning_rate': 1.9412258606213266e-05, 'epoch': 0.09}\n",
            "{'loss': 0.6128, 'grad_norm': 8.430987358093262, 'learning_rate': 1.932829554995802e-05, 'epoch': 0.1}\n",
            "{'loss': 0.6199, 'grad_norm': 11.042398452758789, 'learning_rate': 1.9244332493702774e-05, 'epoch': 0.11}\n",
            "{'loss': 0.553, 'grad_norm': 13.021499633789062, 'learning_rate': 1.9160369437447525e-05, 'epoch': 0.13}\n",
            "{'loss': 0.5415, 'grad_norm': 12.313055992126465, 'learning_rate': 1.9076406381192276e-05, 'epoch': 0.14}\n",
            "{'loss': 0.5347, 'grad_norm': 9.906603813171387, 'learning_rate': 1.899244332493703e-05, 'epoch': 0.15}\n",
            "{'loss': 0.5473, 'grad_norm': 9.218281745910645, 'learning_rate': 1.890848026868178e-05, 'epoch': 0.16}\n",
            "{'loss': 0.5115, 'grad_norm': 11.573504447937012, 'learning_rate': 1.8824517212426535e-05, 'epoch': 0.18}\n",
            "{'loss': 0.4528, 'grad_norm': 11.80951976776123, 'learning_rate': 1.8740554156171285e-05, 'epoch': 0.19}\n",
            "{'loss': 0.4565, 'grad_norm': 9.306434631347656, 'learning_rate': 1.865659109991604e-05, 'epoch': 0.2}\n",
            "{'loss': 0.4241, 'grad_norm': 9.986526489257812, 'learning_rate': 1.857262804366079e-05, 'epoch': 0.21}\n",
            "{'loss': 0.4356, 'grad_norm': 11.021135330200195, 'learning_rate': 1.8488664987405544e-05, 'epoch': 0.23}\n",
            "{'loss': 0.4228, 'grad_norm': 9.949380874633789, 'learning_rate': 1.8404701931150295e-05, 'epoch': 0.24}\n",
            "{'loss': 0.4244, 'grad_norm': 12.504668235778809, 'learning_rate': 1.832073887489505e-05, 'epoch': 0.25}\n",
            "{'loss': 0.4302, 'grad_norm': 12.31444263458252, 'learning_rate': 1.82367758186398e-05, 'epoch': 0.26}\n",
            "{'loss': 0.4103, 'grad_norm': 11.103362083435059, 'learning_rate': 1.8152812762384553e-05, 'epoch': 0.28}\n",
            "{'loss': 0.4204, 'grad_norm': 10.716175079345703, 'learning_rate': 1.8068849706129304e-05, 'epoch': 0.29}\n",
            "{'loss': 0.361, 'grad_norm': 10.684788703918457, 'learning_rate': 1.7984886649874055e-05, 'epoch': 0.3}\n",
            "{'loss': 0.3904, 'grad_norm': 13.742345809936523, 'learning_rate': 1.790092359361881e-05, 'epoch': 0.31}\n",
            "{'loss': 0.3998, 'grad_norm': 12.53758430480957, 'learning_rate': 1.7816960537363563e-05, 'epoch': 0.33}\n",
            "{'loss': 0.4159, 'grad_norm': 13.98347282409668, 'learning_rate': 1.7732997481108313e-05, 'epoch': 0.34}\n",
            "{'loss': 0.379, 'grad_norm': 18.09482192993164, 'learning_rate': 1.7649034424853067e-05, 'epoch': 0.35}\n",
            "{'loss': 0.3832, 'grad_norm': 12.03035831451416, 'learning_rate': 1.7565071368597818e-05, 'epoch': 0.37}\n",
            "{'loss': 0.3778, 'grad_norm': 10.405396461486816, 'learning_rate': 1.7481108312342572e-05, 'epoch': 0.38}\n",
            "{'loss': 0.381, 'grad_norm': 11.820718765258789, 'learning_rate': 1.7397145256087323e-05, 'epoch': 0.39}\n",
            "{'loss': 0.3598, 'grad_norm': 14.872633934020996, 'learning_rate': 1.7313182199832074e-05, 'epoch': 0.4}\n",
            "{'loss': 0.3692, 'grad_norm': 12.125962257385254, 'learning_rate': 1.7229219143576828e-05, 'epoch': 0.42}\n",
            "{'loss': 0.3777, 'grad_norm': 12.564290046691895, 'learning_rate': 1.714525608732158e-05, 'epoch': 0.43}\n",
            "{'loss': 0.3874, 'grad_norm': 11.884758949279785, 'learning_rate': 1.7061293031066332e-05, 'epoch': 0.44}\n",
            "{'loss': 0.3897, 'grad_norm': 10.021536827087402, 'learning_rate': 1.6977329974811086e-05, 'epoch': 0.45}\n",
            "{'loss': 0.3619, 'grad_norm': 11.495000839233398, 'learning_rate': 1.6893366918555837e-05, 'epoch': 0.47}\n",
            "{'loss': 0.3772, 'grad_norm': 12.242470741271973, 'learning_rate': 1.6809403862300588e-05, 'epoch': 0.48}\n",
            "{'loss': 0.3491, 'grad_norm': 14.454459190368652, 'learning_rate': 1.672544080604534e-05, 'epoch': 0.49}\n",
            "{'loss': 0.366, 'grad_norm': 12.196849822998047, 'learning_rate': 1.6641477749790092e-05, 'epoch': 0.5}\n",
            "{'loss': 0.3964, 'grad_norm': 14.8052396774292, 'learning_rate': 1.6557514693534846e-05, 'epoch': 0.52}\n",
            "{'loss': 0.3642, 'grad_norm': 13.43660831451416, 'learning_rate': 1.64735516372796e-05, 'epoch': 0.53}\n",
            "{'loss': 0.3661, 'grad_norm': 14.123509407043457, 'learning_rate': 1.6397984886649875e-05, 'epoch': 0.54}\n",
            "{'loss': 0.3509, 'grad_norm': 16.408193588256836, 'learning_rate': 1.6322418136020153e-05, 'epoch': 0.55}\n",
            "{'loss': 0.3616, 'grad_norm': 11.970232963562012, 'learning_rate': 1.6238455079764907e-05, 'epoch': 0.57}\n",
            "{'loss': 0.3425, 'grad_norm': 12.452380180358887, 'learning_rate': 1.6154492023509658e-05, 'epoch': 0.58}\n",
            "{'loss': 0.3765, 'grad_norm': 13.35214614868164, 'learning_rate': 1.607052896725441e-05, 'epoch': 0.59}\n",
            "{'loss': 0.3328, 'grad_norm': 14.228165626525879, 'learning_rate': 1.5986565910999162e-05, 'epoch': 0.6}\n",
            "{'loss': 0.3548, 'grad_norm': 11.193962097167969, 'learning_rate': 1.5902602854743913e-05, 'epoch': 0.62}\n",
            "{'loss': 0.3745, 'grad_norm': 12.053017616271973, 'learning_rate': 1.5818639798488667e-05, 'epoch': 0.63}\n",
            "{'loss': 0.3516, 'grad_norm': 18.41685676574707, 'learning_rate': 1.5734676742233418e-05, 'epoch': 0.64}\n",
            "{'loss': 0.34, 'grad_norm': 13.535322189331055, 'learning_rate': 1.5650713685978172e-05, 'epoch': 0.65}\n",
            "{'loss': 0.3421, 'grad_norm': 13.491226196289062, 'learning_rate': 1.5566750629722926e-05, 'epoch': 0.67}\n",
            "{'loss': 0.3584, 'grad_norm': 12.633179664611816, 'learning_rate': 1.5482787573467673e-05, 'epoch': 0.68}\n",
            "{'loss': 0.3326, 'grad_norm': 13.139580726623535, 'learning_rate': 1.5398824517212427e-05, 'epoch': 0.69}\n",
            "{'loss': 0.3365, 'grad_norm': 10.929363250732422, 'learning_rate': 1.531486146095718e-05, 'epoch': 0.7}\n",
            "{'loss': 0.3568, 'grad_norm': 12.580230712890625, 'learning_rate': 1.5230898404701932e-05, 'epoch': 0.72}\n",
            "{'loss': 0.3254, 'grad_norm': 12.744074821472168, 'learning_rate': 1.5146935348446686e-05, 'epoch': 0.73}\n",
            "{'loss': 0.3412, 'grad_norm': 13.714911460876465, 'learning_rate': 1.5062972292191438e-05, 'epoch': 0.74}\n",
            "{'loss': 0.3352, 'grad_norm': 13.462656021118164, 'learning_rate': 1.4979009235936189e-05, 'epoch': 0.76}\n",
            "{'loss': 0.3303, 'grad_norm': 12.487210273742676, 'learning_rate': 1.4895046179680941e-05, 'epoch': 0.77}\n",
            "{'loss': 0.3566, 'grad_norm': 12.230891227722168, 'learning_rate': 1.4811083123425694e-05, 'epoch': 0.78}\n",
            "{'loss': 0.3536, 'grad_norm': 12.713946342468262, 'learning_rate': 1.4727120067170446e-05, 'epoch': 0.79}\n",
            "{'loss': 0.338, 'grad_norm': 12.509801864624023, 'learning_rate': 1.4643157010915198e-05, 'epoch': 0.81}\n",
            "{'loss': 0.3368, 'grad_norm': 12.107297897338867, 'learning_rate': 1.455919395465995e-05, 'epoch': 0.82}\n",
            "{'loss': 0.3479, 'grad_norm': 13.727093696594238, 'learning_rate': 1.4475230898404705e-05, 'epoch': 0.83}\n",
            "{'loss': 0.3235, 'grad_norm': 13.172296524047852, 'learning_rate': 1.4391267842149454e-05, 'epoch': 0.84}\n",
            "{'loss': 0.3484, 'grad_norm': 12.65107536315918, 'learning_rate': 1.4307304785894208e-05, 'epoch': 0.86}\n",
            "{'loss': 0.3623, 'grad_norm': 15.467044830322266, 'learning_rate': 1.422334172963896e-05, 'epoch': 0.87}\n",
            "{'loss': 0.3539, 'grad_norm': 11.483333587646484, 'learning_rate': 1.4139378673383712e-05, 'epoch': 0.88}\n",
            "{'loss': 0.3325, 'grad_norm': 14.219367980957031, 'learning_rate': 1.4055415617128465e-05, 'epoch': 0.89}\n",
            "{'loss': 0.3356, 'grad_norm': 11.64149284362793, 'learning_rate': 1.3971452560873217e-05, 'epoch': 0.91}\n",
            "{'loss': 0.3278, 'grad_norm': 12.978862762451172, 'learning_rate': 1.388748950461797e-05, 'epoch': 0.92}\n",
            "{'loss': 0.328, 'grad_norm': 12.37604808807373, 'learning_rate': 1.380352644836272e-05, 'epoch': 0.93}\n",
            "{'loss': 0.3397, 'grad_norm': 14.103720664978027, 'learning_rate': 1.3719563392107474e-05, 'epoch': 0.94}\n",
            "{'loss': 0.3621, 'grad_norm': 11.95491886138916, 'learning_rate': 1.3635600335852227e-05, 'epoch': 0.96}\n",
            "{'loss': 0.3468, 'grad_norm': 13.607587814331055, 'learning_rate': 1.3551637279596979e-05, 'epoch': 0.97}\n",
            "{'loss': 0.3257, 'grad_norm': 13.52284049987793, 'learning_rate': 1.3467674223341731e-05, 'epoch': 0.98}\n",
            "{'loss': 0.3682, 'grad_norm': 14.121527671813965, 'learning_rate': 1.3383711167086484e-05, 'epoch': 0.99}\n",
            "{'loss': 0.3274, 'grad_norm': 14.485923767089844, 'learning_rate': 1.3299748110831234e-05, 'epoch': 1.01}\n",
            "{'loss': 0.3155, 'grad_norm': 13.673650741577148, 'learning_rate': 1.3215785054575987e-05, 'epoch': 1.02}\n",
            "{'loss': 0.3168, 'grad_norm': 11.975356101989746, 'learning_rate': 1.3131821998320739e-05, 'epoch': 1.03}\n",
            "{'loss': 0.3049, 'grad_norm': 13.063949584960938, 'learning_rate': 1.3047858942065493e-05, 'epoch': 1.04}\n",
            "{'loss': 0.3076, 'grad_norm': 14.405157089233398, 'learning_rate': 1.2963895885810245e-05, 'epoch': 1.06}\n",
            "{'loss': 0.3288, 'grad_norm': 16.68721580505371, 'learning_rate': 1.2879932829554998e-05, 'epoch': 1.07}\n",
            "{'loss': 0.3363, 'grad_norm': 12.804097175598145, 'learning_rate': 1.279596977329975e-05, 'epoch': 1.08}\n",
            "{'loss': 0.3139, 'grad_norm': 15.524069786071777, 'learning_rate': 1.27120067170445e-05, 'epoch': 1.1}\n",
            "{'loss': 0.3127, 'grad_norm': 12.402111053466797, 'learning_rate': 1.2628043660789253e-05, 'epoch': 1.11}\n",
            "{'loss': 0.3215, 'grad_norm': 14.99219036102295, 'learning_rate': 1.2544080604534005e-05, 'epoch': 1.12}\n",
            "{'loss': 0.3326, 'grad_norm': 19.078020095825195, 'learning_rate': 1.2460117548278758e-05, 'epoch': 1.13}\n",
            "{'loss': 0.3231, 'grad_norm': 13.088655471801758, 'learning_rate': 1.2376154492023512e-05, 'epoch': 1.15}\n",
            "{'loss': 0.3263, 'grad_norm': 12.66712474822998, 'learning_rate': 1.2292191435768264e-05, 'epoch': 1.16}\n",
            "{'loss': 0.3156, 'grad_norm': 15.375577926635742, 'learning_rate': 1.2208228379513017e-05, 'epoch': 1.17}\n",
            "{'loss': 0.3145, 'grad_norm': 15.474405288696289, 'learning_rate': 1.2124265323257767e-05, 'epoch': 1.18}\n",
            "{'loss': 0.3439, 'grad_norm': 16.858097076416016, 'learning_rate': 1.204030226700252e-05, 'epoch': 1.2}\n",
            "{'loss': 0.3147, 'grad_norm': 13.232598304748535, 'learning_rate': 1.1956339210747272e-05, 'epoch': 1.21}\n",
            "{'loss': 0.3036, 'grad_norm': 19.051469802856445, 'learning_rate': 1.1872376154492024e-05, 'epoch': 1.22}\n",
            "{'loss': 0.3254, 'grad_norm': 14.393728256225586, 'learning_rate': 1.1788413098236777e-05, 'epoch': 1.23}\n",
            "{'loss': 0.3092, 'grad_norm': 12.062654495239258, 'learning_rate': 1.170445004198153e-05, 'epoch': 1.25}\n",
            "{'loss': 0.3308, 'grad_norm': 16.829591751098633, 'learning_rate': 1.162048698572628e-05, 'epoch': 1.26}\n",
            "{'loss': 0.3133, 'grad_norm': 14.597350120544434, 'learning_rate': 1.1536523929471034e-05, 'epoch': 1.27}\n",
            "{'loss': 0.3114, 'grad_norm': 14.076169967651367, 'learning_rate': 1.1452560873215786e-05, 'epoch': 1.28}\n",
            "{'loss': 0.3152, 'grad_norm': 14.074807167053223, 'learning_rate': 1.1368597816960538e-05, 'epoch': 1.3}\n",
            "{'loss': 0.3165, 'grad_norm': 16.440719604492188, 'learning_rate': 1.128463476070529e-05, 'epoch': 1.31}\n",
            "{'loss': 0.3117, 'grad_norm': 13.037361145019531, 'learning_rate': 1.1200671704450043e-05, 'epoch': 1.32}\n",
            "{'loss': 0.3087, 'grad_norm': 17.550891876220703, 'learning_rate': 1.1116708648194795e-05, 'epoch': 1.33}\n",
            "{'loss': 0.3093, 'grad_norm': 12.764413833618164, 'learning_rate': 1.1032745591939546e-05, 'epoch': 1.35}\n",
            "{'loss': 0.3155, 'grad_norm': 13.18188190460205, 'learning_rate': 1.0948782535684298e-05, 'epoch': 1.36}\n",
            "{'loss': 0.3037, 'grad_norm': 14.370975494384766, 'learning_rate': 1.0864819479429052e-05, 'epoch': 1.37}\n",
            "{'loss': 0.3026, 'grad_norm': 13.678343772888184, 'learning_rate': 1.0780856423173805e-05, 'epoch': 1.38}\n",
            "{'loss': 0.2993, 'grad_norm': 15.316844940185547, 'learning_rate': 1.0696893366918557e-05, 'epoch': 1.4}\n",
            "{'loss': 0.3144, 'grad_norm': 17.322837829589844, 'learning_rate': 1.061293031066331e-05, 'epoch': 1.41}\n",
            "{'loss': 0.3071, 'grad_norm': 16.99991798400879, 'learning_rate': 1.0528967254408062e-05, 'epoch': 1.42}\n",
            "{'loss': 0.311, 'grad_norm': 13.147383689880371, 'learning_rate': 1.0445004198152813e-05, 'epoch': 1.43}\n",
            "{'loss': 0.31, 'grad_norm': 16.237672805786133, 'learning_rate': 1.0361041141897565e-05, 'epoch': 1.45}\n",
            "{'loss': 0.3011, 'grad_norm': 15.30878734588623, 'learning_rate': 1.0277078085642317e-05, 'epoch': 1.46}\n",
            "{'loss': 0.3082, 'grad_norm': 14.204298973083496, 'learning_rate': 1.0193115029387071e-05, 'epoch': 1.47}\n",
            "{'loss': 0.2988, 'grad_norm': 15.18246841430664, 'learning_rate': 1.0109151973131824e-05, 'epoch': 1.49}\n",
            "{'loss': 0.3053, 'grad_norm': 14.501974105834961, 'learning_rate': 1.0025188916876576e-05, 'epoch': 1.5}\n",
            "{'loss': 0.3032, 'grad_norm': 16.751291275024414, 'learning_rate': 9.941225860621327e-06, 'epoch': 1.51}\n",
            "{'loss': 0.2946, 'grad_norm': 17.046077728271484, 'learning_rate': 9.85726280436608e-06, 'epoch': 1.52}\n",
            "{'loss': 0.3082, 'grad_norm': 14.762750625610352, 'learning_rate': 9.773299748110831e-06, 'epoch': 1.54}\n",
            "{'loss': 0.2969, 'grad_norm': 15.65905475616455, 'learning_rate': 9.689336691855584e-06, 'epoch': 1.55}\n",
            "{'loss': 0.3046, 'grad_norm': 17.044231414794922, 'learning_rate': 9.605373635600336e-06, 'epoch': 1.56}\n",
            "{'loss': 0.3106, 'grad_norm': 17.689834594726562, 'learning_rate': 9.521410579345088e-06, 'epoch': 1.57}\n",
            "{'loss': 0.3029, 'grad_norm': 14.563314437866211, 'learning_rate': 9.43744752308984e-06, 'epoch': 1.59}\n",
            "{'loss': 0.3065, 'grad_norm': 17.28034019470215, 'learning_rate': 9.353484466834593e-06, 'epoch': 1.6}\n",
            "{'loss': 0.294, 'grad_norm': 17.250558853149414, 'learning_rate': 9.269521410579347e-06, 'epoch': 1.61}\n",
            "{'loss': 0.3003, 'grad_norm': 18.5253963470459, 'learning_rate': 9.185558354324098e-06, 'epoch': 1.62}\n",
            "{'loss': 0.3128, 'grad_norm': 14.771488189697266, 'learning_rate': 9.10159529806885e-06, 'epoch': 1.64}\n",
            "{'loss': 0.294, 'grad_norm': 15.676397323608398, 'learning_rate': 9.017632241813602e-06, 'epoch': 1.65}\n",
            "{'loss': 0.2905, 'grad_norm': 17.056032180786133, 'learning_rate': 8.933669185558355e-06, 'epoch': 1.66}\n",
            "{'loss': 0.3017, 'grad_norm': 15.369802474975586, 'learning_rate': 8.849706129303107e-06, 'epoch': 1.67}\n",
            "{'loss': 0.3074, 'grad_norm': 15.655570030212402, 'learning_rate': 8.76574307304786e-06, 'epoch': 1.69}\n",
            "{'loss': 0.2887, 'grad_norm': 16.69332504272461, 'learning_rate': 8.681780016792612e-06, 'epoch': 1.7}\n",
            "{'loss': 0.2821, 'grad_norm': 15.156929969787598, 'learning_rate': 8.597816960537364e-06, 'epoch': 1.71}\n",
            "{'loss': 0.2976, 'grad_norm': 15.268092155456543, 'learning_rate': 8.513853904282117e-06, 'epoch': 1.72}\n",
            "{'loss': 0.2847, 'grad_norm': 18.485092163085938, 'learning_rate': 8.429890848026869e-06, 'epoch': 1.74}\n",
            "{'loss': 0.2872, 'grad_norm': 18.50994300842285, 'learning_rate': 8.345927791771621e-06, 'epoch': 1.75}\n",
            "{'loss': 0.2926, 'grad_norm': 17.713783264160156, 'learning_rate': 8.261964735516374e-06, 'epoch': 1.76}\n",
            "{'loss': 0.3093, 'grad_norm': 18.56720542907715, 'learning_rate': 8.178001679261126e-06, 'epoch': 1.77}\n",
            "{'loss': 0.2917, 'grad_norm': 16.376127243041992, 'learning_rate': 8.094038623005878e-06, 'epoch': 1.79}\n",
            "{'loss': 0.3151, 'grad_norm': 17.704303741455078, 'learning_rate': 8.01007556675063e-06, 'epoch': 1.8}\n",
            "{'loss': 0.2983, 'grad_norm': 16.170452117919922, 'learning_rate': 7.926112510495383e-06, 'epoch': 1.81}\n",
            "{'loss': 0.2819, 'grad_norm': 15.944793701171875, 'learning_rate': 7.842149454240135e-06, 'epoch': 1.83}\n",
            "{'loss': 0.2956, 'grad_norm': 23.075599670410156, 'learning_rate': 7.758186397984888e-06, 'epoch': 1.84}\n",
            "{'loss': 0.301, 'grad_norm': 17.40557289123535, 'learning_rate': 7.67422334172964e-06, 'epoch': 1.85}\n",
            "{'loss': 0.32, 'grad_norm': 16.819137573242188, 'learning_rate': 7.5902602854743925e-06, 'epoch': 1.86}\n",
            "{'loss': 0.2882, 'grad_norm': 16.07904052734375, 'learning_rate': 7.506297229219144e-06, 'epoch': 1.88}\n",
            "{'loss': 0.2932, 'grad_norm': 17.68109893798828, 'learning_rate': 7.422334172963896e-06, 'epoch': 1.89}\n",
            "{'loss': 0.3014, 'grad_norm': 15.843936920166016, 'learning_rate': 7.338371116708649e-06, 'epoch': 1.9}\n",
            "{'loss': 0.2861, 'grad_norm': 18.924226760864258, 'learning_rate': 7.254408060453401e-06, 'epoch': 1.91}\n",
            "{'loss': 0.3021, 'grad_norm': 21.829998016357422, 'learning_rate': 7.170445004198153e-06, 'epoch': 1.93}\n",
            "{'loss': 0.2767, 'grad_norm': 17.8551025390625, 'learning_rate': 7.086481947942906e-06, 'epoch': 1.94}\n",
            "{'loss': 0.2885, 'grad_norm': 21.708984375, 'learning_rate': 7.002518891687659e-06, 'epoch': 1.95}\n",
            "{'loss': 0.2839, 'grad_norm': 17.03741455078125, 'learning_rate': 6.9185558354324104e-06, 'epoch': 1.96}\n",
            "{'loss': 0.2861, 'grad_norm': 17.23878288269043, 'learning_rate': 6.834592779177163e-06, 'epoch': 1.98}\n",
            "{'loss': 0.2933, 'grad_norm': 17.60420036315918, 'learning_rate': 6.750629722921915e-06, 'epoch': 1.99}\n",
            "{'loss': 0.2857, 'grad_norm': 20.064233779907227, 'learning_rate': 6.666666666666667e-06, 'epoch': 2.0}\n",
            "{'loss': 0.2826, 'grad_norm': 17.884361267089844, 'learning_rate': 6.58270361041142e-06, 'epoch': 2.01}\n",
            "{'loss': 0.2823, 'grad_norm': 19.06334686279297, 'learning_rate': 6.498740554156172e-06, 'epoch': 2.03}\n",
            "{'loss': 0.2739, 'grad_norm': 18.685171127319336, 'learning_rate': 6.414777497900924e-06, 'epoch': 2.04}\n",
            "{'loss': 0.2726, 'grad_norm': 19.883241653442383, 'learning_rate': 6.330814441645676e-06, 'epoch': 2.05}\n",
            "{'loss': 0.2924, 'grad_norm': 19.068309783935547, 'learning_rate': 6.246851385390429e-06, 'epoch': 2.06}\n",
            "{'loss': 0.2804, 'grad_norm': 20.394020080566406, 'learning_rate': 6.162888329135182e-06, 'epoch': 2.08}\n",
            "{'loss': 0.2832, 'grad_norm': 19.707839965820312, 'learning_rate': 6.078925272879933e-06, 'epoch': 2.09}\n",
            "{'loss': 0.2936, 'grad_norm': 18.87272071838379, 'learning_rate': 5.9949622166246855e-06, 'epoch': 2.1}\n",
            "{'loss': 0.2754, 'grad_norm': 19.655609130859375, 'learning_rate': 5.910999160369439e-06, 'epoch': 2.11}\n",
            "{'loss': 0.2742, 'grad_norm': 20.548337936401367, 'learning_rate': 5.82703610411419e-06, 'epoch': 2.13}\n",
            "{'loss': 0.2842, 'grad_norm': 19.197574615478516, 'learning_rate': 5.7430730478589425e-06, 'epoch': 2.14}\n",
            "{'loss': 0.2798, 'grad_norm': 20.164369583129883, 'learning_rate': 5.659109991603695e-06, 'epoch': 2.15}\n",
            "{'loss': 0.2727, 'grad_norm': 19.885839462280273, 'learning_rate': 5.575146935348446e-06, 'epoch': 2.16}\n",
            "{'loss': 0.2694, 'grad_norm': 19.811931610107422, 'learning_rate': 5.4911838790931996e-06, 'epoch': 2.18}\n",
            "{'loss': 0.278, 'grad_norm': 21.735153198242188, 'learning_rate': 5.407220822837952e-06, 'epoch': 2.19}\n",
            "{'loss': 0.2775, 'grad_norm': 17.31255340576172, 'learning_rate': 5.323257766582704e-06, 'epoch': 2.2}\n",
            "{'loss': 0.273, 'grad_norm': 20.465463638305664, 'learning_rate': 5.239294710327456e-06, 'epoch': 2.22}\n",
            "{'loss': 0.2746, 'grad_norm': 20.962730407714844, 'learning_rate': 5.155331654072209e-06, 'epoch': 2.23}\n",
            "{'loss': 0.29, 'grad_norm': 17.637550354003906, 'learning_rate': 5.071368597816961e-06, 'epoch': 2.24}\n",
            "{'loss': 0.2753, 'grad_norm': 22.086397171020508, 'learning_rate': 4.987405541561714e-06, 'epoch': 2.25}\n",
            "{'loss': 0.2729, 'grad_norm': 17.133258819580078, 'learning_rate': 4.903442485306465e-06, 'epoch': 2.27}\n",
            "{'loss': 0.2863, 'grad_norm': 18.970779418945312, 'learning_rate': 4.819479429051218e-06, 'epoch': 2.28}\n",
            "{'loss': 0.2619, 'grad_norm': 19.726612091064453, 'learning_rate': 4.73551637279597e-06, 'epoch': 2.29}\n",
            "{'loss': 0.2813, 'grad_norm': 21.716753005981445, 'learning_rate': 4.651553316540722e-06, 'epoch': 2.3}\n",
            "{'loss': 0.2698, 'grad_norm': 21.857519149780273, 'learning_rate': 4.567590260285475e-06, 'epoch': 2.32}\n",
            "{'loss': 0.278, 'grad_norm': 21.44426155090332, 'learning_rate': 4.483627204030227e-06, 'epoch': 2.33}\n",
            "{'loss': 0.2681, 'grad_norm': 21.413679122924805, 'learning_rate': 4.399664147774979e-06, 'epoch': 2.34}\n",
            "{'loss': 0.2779, 'grad_norm': 16.467426300048828, 'learning_rate': 4.315701091519732e-06, 'epoch': 2.35}\n",
            "{'loss': 0.2722, 'grad_norm': 20.224830627441406, 'learning_rate': 4.231738035264484e-06, 'epoch': 2.37}\n",
            "{'loss': 0.2677, 'grad_norm': 20.23053550720215, 'learning_rate': 4.147774979009236e-06, 'epoch': 2.38}\n",
            "{'loss': 0.2692, 'grad_norm': 19.03900146484375, 'learning_rate': 4.063811922753989e-06, 'epoch': 2.39}\n",
            "{'loss': 0.2656, 'grad_norm': 19.721181869506836, 'learning_rate': 3.979848866498741e-06, 'epoch': 2.4}\n",
            "{'loss': 0.2734, 'grad_norm': 20.4954776763916, 'learning_rate': 3.895885810243493e-06, 'epoch': 2.42}\n",
            "{'loss': 0.2827, 'grad_norm': 20.032634735107422, 'learning_rate': 3.8119227539882453e-06, 'epoch': 2.43}\n",
            "{'loss': 0.2636, 'grad_norm': 20.795108795166016, 'learning_rate': 3.727959697732998e-06, 'epoch': 2.44}\n",
            "{'loss': 0.2669, 'grad_norm': 22.9765682220459, 'learning_rate': 3.64399664147775e-06, 'epoch': 2.45}\n",
            "{'loss': 0.2812, 'grad_norm': 23.956560134887695, 'learning_rate': 3.560033585222503e-06, 'epoch': 2.47}\n",
            "{'loss': 0.2747, 'grad_norm': 18.886138916015625, 'learning_rate': 3.4760705289672547e-06, 'epoch': 2.48}\n",
            "{'loss': 0.2639, 'grad_norm': 22.66562843322754, 'learning_rate': 3.3921074727120067e-06, 'epoch': 2.49}\n",
            "{'loss': 0.2629, 'grad_norm': 21.825109481811523, 'learning_rate': 3.3081444164567595e-06, 'epoch': 2.5}\n",
            "{'loss': 0.2576, 'grad_norm': 22.084938049316406, 'learning_rate': 3.2241813602015114e-06, 'epoch': 2.52}\n",
            "{'loss': 0.2725, 'grad_norm': 22.790016174316406, 'learning_rate': 3.140218303946264e-06, 'epoch': 2.53}\n",
            "{'loss': 0.2697, 'grad_norm': 18.68769073486328, 'learning_rate': 3.056255247691016e-06, 'epoch': 2.54}\n",
            "{'loss': 0.2782, 'grad_norm': 22.895538330078125, 'learning_rate': 2.9722921914357684e-06, 'epoch': 2.56}\n",
            "{'loss': 0.2824, 'grad_norm': 21.701885223388672, 'learning_rate': 2.888329135180521e-06, 'epoch': 2.57}\n",
            "{'loss': 0.2676, 'grad_norm': 18.513639450073242, 'learning_rate': 2.804366078925273e-06, 'epoch': 2.58}\n",
            "{'loss': 0.262, 'grad_norm': 21.31697654724121, 'learning_rate': 2.7204030226700255e-06, 'epoch': 2.59}\n",
            "{'loss': 0.2639, 'grad_norm': 24.433032989501953, 'learning_rate': 2.636439966414778e-06, 'epoch': 2.61}\n",
            "{'loss': 0.2842, 'grad_norm': 22.917091369628906, 'learning_rate': 2.5524769101595298e-06, 'epoch': 2.62}\n",
            "{'loss': 0.2694, 'grad_norm': 21.6010799407959, 'learning_rate': 2.4685138539042825e-06, 'epoch': 2.63}\n",
            "{'loss': 0.258, 'grad_norm': 21.226417541503906, 'learning_rate': 2.3845507976490345e-06, 'epoch': 2.64}\n",
            "{'loss': 0.265, 'grad_norm': 22.83465576171875, 'learning_rate': 2.300587741393787e-06, 'epoch': 2.66}\n",
            "{'loss': 0.2779, 'grad_norm': 23.309816360473633, 'learning_rate': 2.216624685138539e-06, 'epoch': 2.67}\n",
            "{'loss': 0.2846, 'grad_norm': 19.360637664794922, 'learning_rate': 2.1326616288832915e-06, 'epoch': 2.68}\n",
            "{'loss': 0.2682, 'grad_norm': 19.190086364746094, 'learning_rate': 2.048698572628044e-06, 'epoch': 2.69}\n",
            "{'loss': 0.2825, 'grad_norm': 23.116056442260742, 'learning_rate': 1.9647355163727962e-06, 'epoch': 2.71}\n",
            "{'loss': 0.2782, 'grad_norm': 26.35337257385254, 'learning_rate': 1.8807724601175484e-06, 'epoch': 2.72}\n",
            "{'loss': 0.2591, 'grad_norm': 19.330904006958008, 'learning_rate': 1.7968094038623007e-06, 'epoch': 2.73}\n",
            "{'loss': 0.2646, 'grad_norm': 21.723888397216797, 'learning_rate': 1.712846347607053e-06, 'epoch': 2.74}\n",
            "{'loss': 0.2583, 'grad_norm': 20.800201416015625, 'learning_rate': 1.6288832913518054e-06, 'epoch': 2.76}\n",
            "{'loss': 0.258, 'grad_norm': 20.21783447265625, 'learning_rate': 1.5449202350965576e-06, 'epoch': 2.77}\n",
            "{'loss': 0.2591, 'grad_norm': 25.11338233947754, 'learning_rate': 1.46095717884131e-06, 'epoch': 2.78}\n",
            "{'loss': 0.2661, 'grad_norm': 18.914539337158203, 'learning_rate': 1.3769941225860623e-06, 'epoch': 2.79}\n",
            "{'loss': 0.2658, 'grad_norm': 18.289186477661133, 'learning_rate': 1.2930310663308146e-06, 'epoch': 2.81}\n",
            "{'loss': 0.2712, 'grad_norm': 20.38777732849121, 'learning_rate': 1.2090680100755668e-06, 'epoch': 2.82}\n",
            "{'loss': 0.2724, 'grad_norm': 23.809755325317383, 'learning_rate': 1.1251049538203191e-06, 'epoch': 2.83}\n",
            "{'loss': 0.2704, 'grad_norm': 22.64280128479004, 'learning_rate': 1.0411418975650715e-06, 'epoch': 2.84}\n",
            "{'loss': 0.2639, 'grad_norm': 20.203590393066406, 'learning_rate': 9.571788413098238e-07, 'epoch': 2.86}\n",
            "{'loss': 0.2649, 'grad_norm': 22.89038848876953, 'learning_rate': 8.732157850545761e-07, 'epoch': 2.87}\n",
            "{'loss': 0.2554, 'grad_norm': 19.067174911499023, 'learning_rate': 7.892527287993283e-07, 'epoch': 2.88}\n",
            "{'loss': 0.2581, 'grad_norm': 20.266223907470703, 'learning_rate': 7.052896725440807e-07, 'epoch': 2.89}\n",
            "{'loss': 0.2656, 'grad_norm': 20.74699592590332, 'learning_rate': 6.213266162888329e-07, 'epoch': 2.91}\n",
            "{'loss': 0.2664, 'grad_norm': 21.580751419067383, 'learning_rate': 5.373635600335853e-07, 'epoch': 2.92}\n",
            "{'loss': 0.2574, 'grad_norm': 22.283355712890625, 'learning_rate': 4.5340050377833756e-07, 'epoch': 2.93}\n",
            "{'loss': 0.2635, 'grad_norm': 22.60944175720215, 'learning_rate': 3.694374475230899e-07, 'epoch': 2.95}\n",
            "{'loss': 0.266, 'grad_norm': 21.927608489990234, 'learning_rate': 2.8547439126784216e-07, 'epoch': 2.96}\n",
            "{'loss': 0.2674, 'grad_norm': 20.815279006958008, 'learning_rate': 2.0151133501259446e-07, 'epoch': 2.97}\n",
            "{'loss': 0.2714, 'grad_norm': 21.808427810668945, 'learning_rate': 1.1754827875734677e-07, 'epoch': 2.98}\n",
            "{'loss': 0.2581, 'grad_norm': 18.90435218811035, 'learning_rate': 3.358522250209908e-08, 'epoch': 3.0}\n",
            "{'train_runtime': 322179.4937, 'train_samples_per_second': 0.03, 'train_steps_per_second': 0.007, 'train_loss': 0.34577723259089077, 'epoch': 3.0}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('biomistral_oracle_lora\\\\tokenizer_config.json',\n",
              " 'biomistral_oracle_lora\\\\special_tokens_map.json',\n",
              " 'biomistral_oracle_lora\\\\tokenizer.json')"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
        "from transformers import Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_dir,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=None  # ✅ Do NOT move to device yet\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Apply LoRA\n",
        "peft_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM\n",
        ")\n",
        "model = get_peft_model(model, peft_config)\n",
        "model = model.to(\"cuda\")\n",
        "\n",
        "# Load your dataset\n",
        "data = load_dataset(\"json\", data_files=\"oracle_qa_finetune_data.jsonl\", split=\"train\")\n",
        "\n",
        "# Format prompt\n",
        "def format_example(example):\n",
        "    prompt = f\"\"\"### Instruction:\n",
        "You are a patient. Answer the doctor's question based on the patient context given. \n",
        "Use lay language only. Please be concise and answer in one or two short sentences.\n",
        "\n",
        "### Input:\n",
        "{example['input']}\n",
        "\n",
        "### Response:\n",
        "{example['output']}\"\"\"\n",
        "\n",
        "    return {\"text\": prompt}\n",
        "\n",
        "data = data.map(format_example)\n",
        "tokenized = data.map(lambda x: tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", max_length=512), batched=True)\n",
        "\n",
        "# Training config\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./biomistral_oracle_lora\",\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    fp16=True,\n",
        "    logging_steps=10,\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized,\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "model.save_pretrained(\"biomistral_oracle_lora\")\n",
        "tokenizer.save_pretrained(\"biomistral_oracle_lora\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): MistralForCausalLM(\n",
              "      (model): MistralModel(\n",
              "        (embed_tokens): Embedding(32000, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x MistralDecoderLayer(\n",
              "            (self_attn): MistralSdpaAttention(\n",
              "              (q_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "              (v_proj): lora.Linear(\n",
              "                (base_layer): Linear(in_features=4096, out_features=1024, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=16, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=16, out_features=1024, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
              "              (rotary_emb): MistralRotaryEmbedding()\n",
              "            )\n",
              "            (mlp): MistralMLP(\n",
              "              (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "              (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
              "              (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
              "              (act_fn): SiLU()\n",
              "            )\n",
              "            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "\n",
        "# Path to LoRA adapter and tokenizer\n",
        "adapter_path = \"biomistral_oracle_lora\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
        "\n",
        "# Load base model (BioMistral-7B) — assumes you have it locally or access to Hugging Face\n",
        "base_model_dir = \"./biomistral-7b/models--biomistral--biomistral-7b/snapshots/9a11e1ffa817c211cbb52ee1fb312dc6b61b40a5\"\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_dir,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"auto\"\n",
        ")\n",
        "\n",
        "# Load LoRA adapter\n",
        "model = PeftModel.from_pretrained(\n",
        "    base_model,\n",
        "    adapter_path,\n",
        "    torch_dtype=\"auto\"\n",
        ")\n",
        "\n",
        "model.eval()  # Optional: set to eval mode for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = model.to(\"cuda\")\n",
        "next(model.parameters()).device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's evaluate with some random samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\young\\anaconda3\\envs\\aihc-ml\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "c:\\Users\\young\\anaconda3\\envs\\aihc-ml\\lib\\site-packages\\transformers\\models\\mistral\\modeling_mistral.py:456: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Input Prompt:\n",
            " ### Instruction:\n",
            "    You are a patient. Answer the doctor's question based on the patient context given. \n",
            "    Use lay language only. Please be concise and answer in one or two short sentences.\n",
            "\n",
            "    ### Input:\n",
            "    Patient Info:\n",
            "Age: 30\n",
            "Gender: M\n",
            "Location: Boston, Massachusetts\n",
            "Conditions: Perennial allergic rhinitis with seasonal variation; Chronic sinusitis (disorder); Acute bronchitis (disorder); Viral sinusitis (disorder); Laceration of foot; Streptococcal sore throat (disorder); Suspected COVID-19; COVID-19\n",
            "Observations:\n",
            "- Peanut IgE Ab in Serum: 0.0\n",
            "- Walnut IgE Ab in Serum: 0.3\n",
            "- Codfish IgE Ab in Serum: 0.3\n",
            "- Shrimp IgE Ab in Serum: 0.3\n",
            "- Wheat IgE Ab in Serum: 0.0\n",
            "- Egg white IgE Ab in Serum: 0.3\n",
            "- Soybean IgE Ab in Serum: 0.2\n",
            "- Cow milk IgE Ab in Serum: 0.3\n",
            "- White oak IgE Ab in Serum: 0.1\n",
            "- Common Ragweed IgE Ab in Serum: 0.1\n",
            "Question: How is your foot feeling after the laceration?\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "\n",
            "🧠 Model Response:\n",
            " It's been healing well, but it's still a bit sore.\n",
            "\n",
            "✅ Expected (Fine-Tuned) Answer:\n",
            " My foot is still sore and tender where the cut is.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Input Prompt:\n",
            " ### Instruction:\n",
            "    You are a patient. Answer the doctor's question based on the patient context given. \n",
            "    Use lay language only. Please be concise and answer in one or two short sentences.\n",
            "\n",
            "    ### Input:\n",
            "    Patient Info:\n",
            "Age: 73\n",
            "Gender: F\n",
            "Location: Northampton, Massachusetts\n",
            "Conditions: Miscarriage in first trimester; Normal pregnancy; Viral sinusitis (disorder); Acute bronchitis (disorder); Primary fibromyalgia syndrome; Chronic obstructive bronchitis (disorder); Osteoarthritis of knee\n",
            "Observations:\n",
            "- Body Height: 164.3\n",
            "- Pain severity - 0-10 verbal numeric rating [Score] - Reported: 2.0\n",
            "- Body Weight: 75.4\n",
            "- Body Mass Index: 27.9\n",
            "- Diastolic Blood Pressure: 86.0\n",
            "- Systolic Blood Pressure: 123.0\n",
            "- Heart rate: 67.0\n",
            "- Respiratory rate: 14.0\n",
            "- Total Cholesterol: 185.3\n",
            "- Triglycerides: 146.2\n",
            "Question: Have you experienced any sudden vision changes?\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "\n",
            "🧠 Model Response:\n",
            " I'm not sure. I haven't really paid attention to my vision.\n",
            "\n",
            "✅ Expected (Fine-Tuned) Answer:\n",
            " I don't think so, but I haven't really noticed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Input Prompt:\n",
            " ### Instruction:\n",
            "    You are a patient. Answer the doctor's question based on the patient context given. \n",
            "    Use lay language only. Please be concise and answer in one or two short sentences.\n",
            "\n",
            "    ### Input:\n",
            "    Patient Info:\n",
            "Age: 67\n",
            "Gender: M\n",
            "Location: Pepperell, Massachusetts\n",
            "Conditions: Hypertension; Chronic sinusitis (disorder); Viral sinusitis (disorder); Coronary Heart Disease; Acute viral pharyngitis (disorder); Stroke\n",
            "Observations:\n",
            "- Body Height: 174.5\n",
            "- Pain severity - 0-10 verbal numeric rating [Score] - Reported: 3.0\n",
            "- Body Weight: 87.3\n",
            "- Body Mass Index: 28.7\n",
            "- Diastolic Blood Pressure: 108.0\n",
            "- Systolic Blood Pressure: 170.0\n",
            "- Heart rate: 98.0\n",
            "- Respiratory rate: 12.0\n",
            "- Tobacco smoking status NHIS: Never smoker\n",
            "- In the past year  have you been afraid of your partner or ex-partner?: No\n",
            "Question: Have you experienced any unusual skin rashes or itching lately?\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "\n",
            "🧠 Model Response:\n",
            " I'm not sure. I haven't really noticed anything like that.\n",
            "\n",
            "✅ Expected (Fine-Tuned) Answer:\n",
            " I don't think so. I haven't noticed anything like that.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Input Prompt:\n",
            " ### Instruction:\n",
            "    You are a patient. Answer the doctor's question based on the patient context given. \n",
            "    Use lay language only. Please be concise and answer in one or two short sentences.\n",
            "\n",
            "    ### Input:\n",
            "    Patient Info:\n",
            "Age: 58\n",
            "Gender: F\n",
            "Location: Holyoke, Massachusetts\n",
            "Conditions: Hyperlipidemia; Viral sinusitis (disorder); Normal pregnancy; Miscarriage in first trimester; Blighted ovum; Localized  primary osteoarthritis of the hand; Fracture subluxation of wrist; Suspected lung cancer (situation); Non-small cell lung cancer (disorder); Anemia (disorder)\n",
            "Observations:\n",
            "- Glucose: 92.8\n",
            "- Urea Nitrogen: 8.5\n",
            "- Creatinine: 3.1\n",
            "- Calcium: 9.3\n",
            "- Sodium: 136.9\n",
            "- Potassium: 4.3\n",
            "- Chloride: 101.8\n",
            "- Carbon Dioxide: 27.1\n",
            "- Glomerular filtration rate/1.73 sq M.predicted: 78.3\n",
            "- Protein [Mass/volume] in Serum or Plasma: 64.8\n",
            "Question: Do you experience frequent headaches?\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "\n",
            "🧠 Model Response:\n",
            " I'm not sure. I don't think I've had any headaches recently.\n",
            "\n",
            "✅ Expected (Fine-Tuned) Answer:\n",
            " I'm not sure, I don't really keep track of my headaches.\n",
            "\n",
            "🔍 Input Prompt:\n",
            " ### Instruction:\n",
            "    You are a patient. Answer the doctor's question based on the patient context given. \n",
            "    Use lay language only. Please be concise and answer in one or two short sentences.\n",
            "\n",
            "    ### Input:\n",
            "    Patient Info:\n",
            "Age: 35\n",
            "Gender: M\n",
            "Location: Wakefield, Massachusetts\n",
            "Conditions: Prediabetes; Anemia (disorder)\n",
            "Observations:\n",
            "- Body Height: 171.8\n",
            "- Pain severity - 0-10 verbal numeric rating [Score] - Reported: 1.0\n",
            "- Body Weight: 83.3\n",
            "- Body Mass Index: 28.2\n",
            "- Diastolic Blood Pressure: 80.0\n",
            "- Systolic Blood Pressure: 105.0\n",
            "- Heart rate: 69.0\n",
            "- Respiratory rate: 12.0\n",
            "- Leukocytes [#/volume] in Blood by Automated count: 10.1\n",
            "- Erythrocytes [#/volume] in Blood by Automated count: 4.0\n",
            "Question: Have you noticed any visual disturbances like blurriness or double vision?\n",
            "\n",
            "    ### Response:\n",
            "    \n",
            "\n",
            "🧠 Model Response:\n",
            " I'm not sure. I haven't really paid attention to my vision.\n",
            "\n",
            "✅ Expected (Fine-Tuned) Answer:\n",
            " I'm not sure. I haven't really thought about it.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "# run 5 sample\n",
        "for _ in range(5):\n",
        "    # Load a QA sample from your dataset\n",
        "    with open(\"oracle_qa_finetune_data.json\", \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "        sample = json.loads(random.choice(lines))\n",
        "\n",
        "    # Unpack the fields\n",
        "    instruction = sample[\"instruction\"]\n",
        "    input_block = sample[\"input\"]\n",
        "    true_output = sample[\"output\"]\n",
        "\n",
        "\n",
        "    # Format prompt using your real training example\n",
        "    prompt = f\"\"\"### Instruction:\n",
        "    You are a patient. Answer the doctor's question based on the patient context given. \n",
        "    Use lay language only. Please be concise and answer in one or two short sentences.\n",
        "\n",
        "    ### Input:\n",
        "    {input_block}\n",
        "\n",
        "    ### Response:\n",
        "    \"\"\"\n",
        "\n",
        "    # Tokenize and generate\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=50,\n",
        "            do_sample=False,\n",
        "            temperature=0.6\n",
        "        )\n",
        "\n",
        "    # Decode\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    model_response = response.split(\"### Response:\")[-1].strip()\n",
        "\n",
        "    # Show comparison\n",
        "    print(\"\\n🔍 Input Prompt:\\n\", prompt)\n",
        "    print(\"\\n🧠 Model Response:\\n\", model_response)\n",
        "    print(\"\\n✅ Expected (Fine-Tuned) Answer:\\n\", true_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems to behave much better."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aihc-ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
